---
title: "project_2_summary"
author: "p swaminathan & pmcdevitt"
date: "23 juillet 2017"
output: html_document
---

***

#### __Introduction__ Required  

***

#### __Data Description__  Required  

***

#### __Exploratory Analysis__ Required  

***

#### __Analysis of Question 1:__  

2. Principal Components (40%)
In this section, you will attempt to better your Kaggle score through the use of principal components.  In this process you must address the assumptions of principal components, produce the interpretations of the eigenvalues, screeplots, and other criterion that aid in selecting components.  In addition, you must also attempt to interpret the components selected with respect to the sale price of the houses.  This may be tough, but do your best.  Furthermore, the investigation of the use of PCA in this project should be used in conjunction with the regression techniques you have already been using (adding categorical variables, investigating OLS, LASSO and coefficients, cross validation, variable selection, etc.)  The team with the best Kaggle score this time around will again earn an extra 3 points.   Simply provide the same table you filled out before with your new scores as well as the code you used to generate it.  As before, only techniques we have learned in this class can be used.  

	Restatement of Problem Required  

Model Selection  
		Type of Selection  
			LASSO, Model Averaging  
			Stepwise, Forward, Backward, Mallows Cp,   
			Manual / Intuition  
			A mix of all of the above.   
			At least two of the above required.  

		Checking Assumptions  
			Residual Plots  
			Influential point analysis (Cook’s D and Leverage)  

		Comparing Competing Models  
			AIC, BIC, adj R2   Required  
			Interval CVPress   Required  
			External Cross Validation Required  
	
	Parameter Interpretation  
		Interpretation (Verbal)  Required  
		Confidence Intervals Required  

***

#### __Analysis Question 2__  

3. LDA (30%)
There is not a lot of actual missing data in this data set as most of the “NA”’s simply indicate the absence of that value.  However, if there were, LDA may be a good method to impute missing categorical variables.  For this part, you will simply use the training set to build a classification model (using LDA) to predict the type of Foundation of houses in the Test Set.  To do this, I will simply select a random sample from the test set and use it to manually test your model.  Similar to the Kaggle competition, each team will provide me with the code that will both train your final classification model and provide predictions given a test set.  We will take this code and run it with the actual training set from Kaggle as well as a randomly drawn subset of the test set with the Foundation type deleted.  The winner of this competition will earn an extra 3 points. 
This section should be written up in a clear and concise manner and should include all the plots, charts, tables and explanation necessary to defend the assumptions of LDA and to validate the fit and performance of your model (confusion matrices, etc.)  




Restatement of Problem Required  

Model Selection  
		Type of Selection  
			LASSO, Model Averaging  
			Stepwise, Forward, Backward, Mallows Cp,  
			Manual / Intuition  
			A mix of all of the above.  
			At least two of the above required.  
 
		Checking Assumptions  
			Residual Plots  
			Influential point analysis (Cook’s D and Leverage)  

		Comparing Competing Models  
			AIC, BIC, adj R2   Required  
			Interval CVPress   Required  
			External Cross Validation Required  
			Kaggle Score Required  
	
###	__Addressing the Assumptions Required__  

###	__Principal Components Analysis Required__  
	
###	__LDA Required__  
:

#### __LDA Assumptions__  

 * Common mean vector for each population  
 * Independently sampled subjects  
 * Multivariate normally distributed data  
 * Variance-covariance matrices for each population as follows:  
 	- Linear discriminant analysis: Σ1 = Σ2 = ... = Σg  
 	- Quadratic discriminant analysis: Σi ≠ Σj  
 	
***

#### __Conclusion/Discussion Required__  
		The conclusion should reprise the questions and conclusions of the introduction,
perhaps augmented by some additional observations or details gleaned from the analysis
section. New questions, future work, etc., can also be raised here.  


***

##### __Appendix Required__  
	Well commented SAS Code Required  
	
	
##### __PCA Analysis__  

```{r, tidy = FALSE, eval = FALSE, highlight = TRUE }


proc datasets lib=work kill nolist memtype=data;
quit;

/* ...	read in training data set	... */

FILENAME REFFILE '/folders/myfolders/stats_i/training_set_cleaned.csv';

PROC IMPORT DATAFILE = REFFILE
	DBMS = CSV
	OUT = home_prices;
	GETNAMES = yes;
RUN;

PROC CONTENTS DATA = home_prices; RUN;

/* ...	read in test data set	... */

filename reffile '/folders/myfolders/stats_i/test_set_cleaned.csv';

proc import datafile = REFFILE
	DBMS = csv
	OUT = test_set;
	GETNAMES = yes;
RUN;

PROC CONTENTS DATA = test_set; RUN;

/* ...	combine train and test data sets		... */

data train_test;
 set home_prices test_set;
run;

/* ...	scatter plots					... */
/* dependent response : log_saleprice	... */

/*
proc sgscatter data = home_prices;
  matrix fullbath
		garagecars
		log_lotfrontage
		overallcond
		overallqual
		log_grlivarea
		totrmsabvgrd
		log_lotarea
		log_saleprice
		garagearea
		bsmtfinsf1
		x2ndflrsf
		totalbsmtsf
		x1stflrsf
		grlivarea
		yearbuilt
		yearremodadd
		/ diagonal=(histogram normal); 
run;
*/

/********************************************************
			second model with principal components
********************************************************/

title 'PCR Using CrossValidation for Component Selection - all selected variables';
proc pls data = home_prices method = pcr cv = one cvtest (stat=press);
class housestyle
		garagetype
		masvnrtype
		neighborhood
		heatingqc
		bsmtqual
		exterqual
		kitchenqual
		bsmtfintype1
		fireplacequ
		foundation
		lotshape
		garagefinish
		mszoning
		electrical
		exterior1st
		exterior2nd
		saletype
		centralair;
model log_saleprice = 
	/*		continuous variables	*/
		fullbath
		garagecars
		log_lotfrontage
		overallcond
		overallqual
		log_grlivarea
		totrmsabvgrd
		log_lotarea
		garagearea
		bsmtfinsf1
		x2ndflrsf
		totalbsmtsf
		x1stflrsf
		grlivarea
		yearbuilt
		yearremodadd
	/*		categorical variables	*/
		housestyle
		garagetype
		masvnrtype
		neighborhood
		heatingqc
		bsmtqual
		exterqual
		kitchenqual
		bsmtfintype1
		fireplacequ
		foundation
		lotshape
		garagefinish
		mszoning
		electrical
		exterior1st
		exterior2nd
		saletype
		centralair;
run;

title 'PCR Using Selected Factors';
proc pls data = train_test method = pcr nfact = 11;
class housestyle
		garagetype
		masvnrtype
		neighborhood
		heatingqc
		bsmtqual
		exterqual
		kitchenqual
		bsmtfintype1
		fireplacequ
		foundation
		lotshape
		garagefinish
		mszoning
		electrical
		exterior1st
		exterior2nd
		saletype
		centralair;
model log_saleprice = 
	/*		continuous variables	*/
		fullbath
		garagecars
		log_lotfrontage
		overallcond
		overallqual
		log_grlivarea
		totrmsabvgrd
		log_lotarea
		garagearea
		bsmtfinsf1
		x2ndflrsf
		totalbsmtsf
		x1stflrsf
		grlivarea
		yearbuilt
		yearremodadd
	/*		categorical variables	*/
		housestyle
		garagetype
		masvnrtype
		neighborhood
		heatingqc
		bsmtqual
		exterqual
		kitchenqual
		bsmtfintype1
		fireplacequ
		foundation
		lotshape
		garagefinish
		mszoning
		electrical
		exterior1st
		exterior2nd
		saletype
		centralair;
		output out = result p = Predict;
run;

/* create kaggle submission file */
/* two columns with appropriate labels. */

proc means data = result Min Max;
run;

proc means data = result noprint;
	var Predict;
    output out = means mean(Predict) = mean_predict;
run;

data kaggle_submit;
set result;
SalePrice = exp(Predict);
if Predict = . then SalePrice = exp(12.018);
keep id SalePrice;
where id > 1460;
run;

proc export data = kaggle_submit replace
   outfile = '/folders/myfolders/stats_ii/kaggle_submit_pca.1.csv'
   dbms = csv;
run;


```


### __SAS LDA Analysis code__  


```{r, tidy = FALSE, eval = FALSE, highlight = TRUE }

/*	...	-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=  */
/* ...	combine train and test data sets		... */
/*	...	-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=  */

data train_test;
 set home_prices test_set;
run;

/*	...	-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=  */

/*proc discrim data = home_prices pool=test crossvalidate testdata = test_set testout = a;*/

proc discrim data = home_prices crossvalidate testdata = test_set testout = a;
	class foundation;
	var fullbath
		garagecars
		log_lotfrontage
		overallcond
		overallqual
		log_grlivarea
		totrmsabvgrd
		log_lotarea
		garagearea
		bsmtfinsf1
		x2ndflrsf
		totalbsmtsf
		x1stflrsf
		grlivarea
		yearbuilt
		yearremodadd;		
   priors "BrkTil" = 0.100
			"CBlock" = 0.434
			"PConc" = 0.443
			"Slab" = 0.016
			"Stone" = 0.004
			"Wood" = 0.002;
run;

proc print;
   run;
```
